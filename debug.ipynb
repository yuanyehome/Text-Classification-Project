{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import mean\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from models import RnnModel, TextCNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import spacy\n",
    "import torch\n",
    "from torchtext import data\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.optim as optim\n",
    "import torch.cuda\n",
    "import nltk\n",
    "from utils import AverageMeter, TextDataset, count_parameters, layer_wise_parameters, human_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/yy/anaconda3/envs/nlp-hw/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)\n",
    "TEXT = data.Field(sequential=True, tokenize=nltk.word_tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def do_validation(model: nn.Module, val_iter):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch in tqdm(val_iter, desc=\"Validating\"):\n",
    "        labels = batch[0]  # [batch_size]\n",
    "        texts = batch[1].t()  # [text_len, batch_size]\n",
    "\n",
    "        output = model(texts)\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        correct_num = torch.sum(predictions == labels).item()\n",
    "\n",
    "        total += len(batch[0])\n",
    "        correct += correct_num\n",
    "    logger.info(\"Validation: total %d items; %d are correct.\" %\n",
    "                (total, correct))\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/yy/anaconda3/envs/nlp-hw/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/home2/yy/anaconda3/envs/nlp-hw/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train, val = data.TabularDataset.splits(\n",
    "    path='merged_data', train='train.csv', validation='dev.csv',\n",
    "    format='csv', skip_header=True,\n",
    "    fields=[('label_id', LABEL), ('text', TEXT)]\n",
    ")\n",
    "test = data.TabularDataset(os.path.join('merged_data', 'test.csv'), format='csv', skip_header=True,\n",
    "                           fields=[('label_id', None), ('text', TEXT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, vectors='glove.840B.300d',\n",
    "                 max_size=10000,\n",
    "                 min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, datas, vocab, device, is_test=False):\n",
    "        self.is_test = is_test\n",
    "        if not is_test:\n",
    "            self.labels = torch.tensor(\n",
    "                list(map(int, datas.label_id))).to(device)\n",
    "        self.features = torch.tensor(list(map(\n",
    "            lambda sentence: list(map(\n",
    "                lambda token: vocab.stoi[token], sentence)),\n",
    "            datas.text\n",
    "        ))).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return self.features[index]\n",
    "        else:\n",
    "            return self.labels[index], self.features[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(text, length):\n",
    "    while len(text) < length:\n",
    "        text.append(\"<pad>\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_item in train:\n",
    "    train_item.text = padding(train_item.text[:200], 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(train, TEXT.vocab, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'),\n",
       " tensor([ 426,  557, 1547,    0,  120,   72,    2,  772,   15,   34,   16,   34,\n",
       "           17,    0,    3,  426,  369,   24,    0, 3372,    7,    0,    3,   50,\n",
       "         3834,  813,  321,    4,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_train = pd.read_csv('data/train.csv')\n",
    "ori_dev = pd.read_csv('data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.read_csv('merged_data/train.csv')\n",
    "new_dev = pd.read_csv('merged_data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(all(ori_train[\"Class Index\"] == new_train[\"label\"]))\n",
    "print(all(ori_train[\"Title\"].apply(lambda s : s.replace('\\\\', ' ')) == new_train[\"title\"]))\n",
    "print(all(ori_train[\"Description\"].apply(lambda s : s.replace('\\\\', ' ')) == new_train[\"description\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(all(ori_dev[\"Class Index\"] == new_dev[\"label\"]))\n",
    "print(all(ori_dev[\"Title\"].apply(lambda s : s.replace('\\\\', ' ')) == new_dev[\"title\"]))\n",
    "print(all(ori_dev[\"Description\"].apply(lambda s : s.replace('\\\\', ' ')) == new_dev[\"description\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-hw",
   "language": "python",
   "name": "nlp-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
